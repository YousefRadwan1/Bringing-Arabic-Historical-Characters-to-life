<!DOCTYPE html>
<html>
  <head>
    <title>Muhammad Ali Pasha ‚Äì The Architect of Modern Egypt</title>
    <style>
      @import url("https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&family=Cinzel:wght@400;600;700&display=swap");

      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body,
      html {
        width: 100%;
        height: 100vh;
        overflow: hidden;
        position: relative;
        font-family: "Amiri", serif;
        background: linear-gradient(
          135deg,
          #0f0f0f 0%,
          #1a1a2e 25%,
          #16213e 50%,
          #0f3460 75%,
          #e94560 100%
        );
        background-size: 400% 400%;
        animation: gradientShift 15s ease infinite;
      }

      @keyframes gradientShift {
        0% {
          background-position: 0% 50%;
        }
        50% {
          background-position: 100% 50%;
        }
        100% {
          background-position: 0% 50%;
        }
      }

      /* Animated particles background */
      .particles {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        pointer-events: none;
        z-index: 1;
      }

      .particle {
        position: absolute;
        width: 2px;
        height: 2px;
        background: rgba(255, 215, 0, 0.6);
        border-radius: 50%;
        animation: float 6s ease-in-out infinite;
      }

      @keyframes float {
        0%,
        100% {
          transform: translateY(0px) rotate(0deg);
          opacity: 0;
        }
        50% {
          transform: translateY(-100px) rotate(180deg);
          opacity: 1;
        }
      }

      #avatar {
        display: block;
        width: 55%;
        height: 100vh;
        position: relative;
        z-index: 2;
        border-right: 3px solid rgba(255, 215, 0, 0.3);
        box-shadow: 0 0 50px rgba(255, 215, 0, 0.2);
      }

      .loading {
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        padding: 20px 40px;
        background: linear-gradient(
          45deg,
          rgba(0, 0, 0, 0.9),
          rgba(20, 20, 60, 0.9)
        );
        border-radius: 15px;
        border: 2px solid #ffd700;
        color: #ffd700;
        font-size: 18px;
        font-weight: bold;
        text-align: center;
        z-index: 1000;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
        animation: pulse 2s infinite;
      }

      @keyframes pulse {
        0%,
        100% {
          transform: translate(-50%, -50%) scale(1);
        }
        50% {
          transform: translate(-50%, -50%) scale(1.05);
        }
      }

      #audioStatus {
        position: fixed;
        bottom: 20px;
        left: 20px;
        padding: 12px 24px;
        background: rgba(0, 0, 0, 0.8);
        border-radius: 25px;
        font-size: 14px;
        color: #ffd700;
        border: 1px solid rgba(255, 215, 0, 0.3);
        backdrop-filter: blur(10px);
        z-index: 100;
      }

      #debugInfo {
        position: fixed;
        top: 20px;
        left: 20px;
        padding: 15px;
        background: rgba(0, 0, 0, 0.9);
        border-radius: 10px;
        font-size: 12px;
        max-width: 350px;
        max-height: 250px;
        overflow: auto;
        display: none;
        color: #00ff88;
        border: 1px solid #00ff88;
        font-family: monospace;
        z-index: 100;
      }

      #controls {
        position: absolute;
        right: 0;
        top: 0;
        width: 45%;
        height: 100vh;
        background: rgba(0, 0, 0, 0.2);
        backdrop-filter: blur(20px);
        border-left: 1px solid rgba(255, 215, 0, 0.3);
        display: flex;
        flex-direction: column;
        justify-content: space-between;
        padding: 40px;
        z-index: 3;
        overflow-y: auto;
      }

      .title-section {
        text-align: center;
        margin-bottom: 30px;
      }

      .main-title {
        font-family: "Cinzel", serif;
        font-size: 2.5rem;
        font-weight: 700;
        color: #ffd700;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);
        margin-bottom: 10px;
        animation: titleGlow 3s ease-in-out infinite alternate;
      }

      @keyframes titleGlow {
        from {
          text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7),
            0 0 20px rgba(255, 215, 0, 0.3);
        }
        to {
          text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7),
            0 0 30px rgba(255, 215, 0, 0.6);
        }
      }

      .subtitle {
        font-family: "Cinzel", serif;
        font-size: 1.2rem;
        color: #c0c0c0;
        font-weight: 400;
        letter-spacing: 2px;
      }

      .description {
        background: rgba(0, 0, 0, 0.4);
        border: 1px solid rgba(255, 215, 0, 0.3);
        border-radius: 15px;
        padding: 25px;
        margin: 20px 0;
        color: #ffffff;
        font-size: 16px;
        line-height: 1.8;
        text-align: justify;
        direction: rtl;
        backdrop-filter: blur(10px);
        box-shadow: inset 0 0 20px rgba(255, 215, 0, 0.1);
      }

      #result {
        background: rgba(0, 0, 0, 0.5);
        border: 1px solid rgba(255, 215, 0, 0.4);
        border-radius: 15px;
        padding: 20px;
        margin: 20px 0;
        color: #ffffff;
        max-height: 200px;
        overflow-y: auto;
        backdrop-filter: blur(10px);
        direction: rtl;
        text-align: right;
        box-shadow: inset 0 0 15px rgba(255, 215, 0, 0.1);
      }

      #result h3 {
        color: #ffd700;
        font-family: "Cinzel", serif;
        margin-bottom: 15px;
        font-size: 1.3rem;
      }

      /* Updated Input Container with proper spacing */
      .input-container {
        display: flex;
        flex-direction: column;
        gap: 20px;
        margin-bottom: 30px;
      }

      .text-input-wrapper {
        display: flex;
        align-items: center;
        gap: 15px;
      }

      #text {
        flex: 1;
        padding: 18px 25px;
        background: rgba(0, 0, 0, 0.6);
        border: 2px solid rgba(255, 215, 0, 0.3);
        border-radius: 25px;
        color: #ffffff;
        font-size: 16px;
        font-family: "Amiri", serif;
        outline: none;
        transition: all 0.3s ease;
        backdrop-filter: blur(10px);
        direction: rtl;
        text-align: right;
      }

      #text::placeholder {
        color: rgba(255, 255, 255, 0.5);
        font-style: italic;
      }

      #text:focus {
        border-color: #ffd700;
        box-shadow: 0 0 25px rgba(255, 215, 0, 0.3);
        background: rgba(0, 0, 0, 0.8);
      }

      /* Creative Button Layout */
      .action-buttons {
        display: flex;
        justify-content: space-between;
        align-items: center;
        gap: 15px;
        padding: 15px;
        background: rgba(0, 0, 0, 0.3);
        border-radius: 20px;
        border: 1px solid rgba(255, 215, 0, 0.2);
        backdrop-filter: blur(10px);
      }

      .button-group {
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 8px;
      }

      .action-button {
        width: 60px;
        height: 60px;
        border: none;
        border-radius: 50%;
        font-size: 24px;
        cursor: pointer;
        transition: all 0.3s ease;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
        position: relative;
        overflow: hidden;
      }

      .action-button::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: inherit;
        border-radius: inherit;
        opacity: 0;
        transition: opacity 0.3s ease;
      }

      .action-button:hover::before {
        opacity: 0.2;
      }

      /* Send Button */
      #sendButton {
        background: linear-gradient(135deg, #4caf50, #45a049);
        color: white;
      }

      #sendButton:hover {
        transform: scale(1.1);
        box-shadow: 0 6px 25px rgba(76, 175, 80, 0.4);
      }

      /* Interactive Chat Button */
      #interactiveChatButton {
        background: linear-gradient(135deg, #2196f3, #1976d2);
        color: white;
      }

      #interactiveChatButton:hover {
        transform: scale(1.1);
        box-shadow: 0 6px 25px rgba(33, 150, 243, 0.4);
      }

      #interactiveChatButton.listening {
        background: linear-gradient(135deg, #ff9800, #f57c00);
        animation: interactivePulse 1s infinite;
      }

      @keyframes interactivePulse {
        0%,
        100% {
          transform: scale(1);
          box-shadow: 0 4px 15px rgba(255, 152, 0, 0.3);
        }
        50% {
          transform: scale(1.1);
          box-shadow: 0 6px 25px rgba(255, 152, 0, 0.6);
        }
      }

      /* Voice Input Button */
      #voiceInputButton {
        background: linear-gradient(135deg, #9c27b0, #7b1fa2);
        color: white;
      }

      #voiceInputButton:hover {
        transform: scale(1.1);
        box-shadow: 0 6px 25px rgba(156, 39, 176, 0.4);
      }

      #voiceInputButton.listening {
        background: linear-gradient(135deg, #e91e63, #c2185b);
        animation: voicePulse 1s infinite;
      }

      @keyframes voicePulse {
        0%,
        100% {
          transform: scale(1);
          box-shadow: 0 4px 15px rgba(233, 30, 99, 0.3);
        }
        50% {
          transform: scale(1.1);
          box-shadow: 0 6px 25px rgba(233, 30, 99, 0.6);
        }
      }

      .button-label {
        font-size: 12px;
        color: #ffd700;
        text-align: center;
        font-weight: 500;
        text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5);
      }

      .control-buttons {
        display: flex;
        gap: 15px;
        justify-content: center;
        margin-top: 20px;
      }

      .control-btn {
        padding: 12px 20px;
        background: rgba(255, 215, 0, 0.1);
        border: 1px solid rgba(255, 215, 0, 0.3);
        border-radius: 25px;
        color: #ffd700;
        font-size: 14px;
        cursor: pointer;
        transition: all 0.3s ease;
        backdrop-filter: blur(10px);
        font-family: "Cinzel", serif;
      }

      .control-btn:hover {
        background: rgba(255, 215, 0, 0.2);
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(255, 215, 0, 0.2);
      }

      .islamic-pattern {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-image: radial-gradient(
            circle at 25% 25%,
            rgba(255, 215, 0, 0.1) 0%,
            transparent 50%
          ),
          radial-gradient(
            circle at 75% 75%,
            rgba(255, 215, 0, 0.1) 0%,
            transparent 50%
          );
        pointer-events: none;
        z-index: 1;
      }

      /* Scrollbar styling */
      ::-webkit-scrollbar {
        width: 8px;
      }

      ::-webkit-scrollbar-track {
        background: rgba(0, 0, 0, 0.3);
        border-radius: 4px;
      }

      ::-webkit-scrollbar-thumb {
        background: rgba(255, 215, 0, 0.5);
        border-radius: 4px;
      }

      ::-webkit-scrollbar-thumb:hover {
        background: rgba(255, 215, 0, 0.7);
      }

      #info {
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        font-size: 24px;
        color: #ffd700;
        font-family: "Cinzel", serif;
        font-weight: 600;
        z-index: 1000;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.8);
      }

      /* Mobile responsiveness */
      @media (max-width: 768px) {
        body {
          flex-direction: column;
        }

        #avatar {
          width: 100%;
          height: 50vh;
          border-right: none;
          border-bottom: 3px solid rgba(255, 215, 0, 0.3);
        }

        #controls {
          position: relative;
          width: 100%;
          height: 50vh;
          padding: 20px;
        }

        .main-title {
          font-size: 1.8rem;
        }

        .description {
          font-size: 14px;
          padding: 15px;
        }

        .action-buttons {
          flex-direction: column;
          gap: 10px;
        }

        .button-group {
          flex-direction: row;
          gap: 15px;
        }

        .action-button {
          width: 50px;
          height: 50px;
          font-size: 20px;
        }
      }
    </style>

    <script type="importmap">
      {
        "imports": {
          "three": "https://cdn.jsdelivr.net/npm/three@0.170.0/build/three.module.js/+esm",
          "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.170.0/examples/jsm/",
          "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.4/modules/talkinghead.mjs"
        }
      }
    </script>
    <script src="https://unpkg.com/@tailwindcss/browser@4"></script>

    <script type="module">
      import { TalkingHead } from "talkinghead";
      let head;
      let recognition;
      let isListeningInteractive = false;
      let isListeningVoiceInput = false;

      // New variables for continuous session
      let isInteractiveSessionActive = false;
      let interactiveSessionTimeout = null;
      let waitingForResponse = false;

      const API_ENDPOINT = "http://localhost:8000/api/ask";

      // ElevenLabs text-to-speech endpoint
      const ttsEndpoint = "https://api.elevenlabs.io/v1/text-to-speech";
      const voicesEndpoint = "https://api.elevenlabs.io/v1/voices";

      // Replace with your actual ElevenLabs API key
      const API_KEY = "sk_33c4cb2c4185970e2ea83a3c74429b1c76585a7735849e09";

      // Default voice ID for ElevenLabs
      const DEFAULT_VOICE_ID = "VMy40598IGgDeaOE8phq"; // Adam voice

      // Speech queue to ensure that async requests get processed in right order
      const speechQueue = [];

      // Debug mode
      const DEBUG = true;

      // Check for Web Audio API support
      if (!window.AudioContext && !window.webkitAudioContext) {
        alert(
          "Your browser doesn't support Web Audio API. Audio playback won't work."
        );
      }

      // Debug logging function
      function debugLog(message, data = null) {
        if (!DEBUG) return;

        const debugInfo = document.getElementById("debugInfo");
        if (!debugInfo) return;

        const timestamp = new Date().toLocaleTimeString();
        let logMessage = `[${timestamp}] ${message}`;

        if (data) {
          console.log(message, data);
          try {
            if (typeof data === "object") {
              logMessage += `: ${JSON.stringify(data).substring(0, 100)}...`;
            } else {
              logMessage += `: ${data}`;
            }
          } catch (e) {
            logMessage += `: [Object]`;
          }
        } else {
          console.log(message);
        }

        debugInfo.innerHTML += `<div>${logMessage}</div>`;
        debugInfo.scrollTop = debugInfo.scrollHeight;

        // Show debug panel
        debugInfo.style.display = "block";
      }

      // Initialize Speech Recognition
      function initializeSpeechRecognition() {
        if (
          "webkitSpeechRecognition" in window ||
          "SpeechRecognition" in window
        ) {
          const SpeechRecognition =
            window.SpeechRecognition || window.webkitSpeechRecognition;
          recognition = new SpeechRecognition();

          recognition.lang = "ar-SA"; // Arabic
          recognition.continuous = false;
          recognition.interimResults = true;
          recognition.maxAlternatives = 1;

          debugLog("Speech recognition initialized successfully");
          return true;
        } else {
          debugLog("Speech recognition not supported");
          // Hide speech buttons if not supported
          document.getElementById("interactiveChatButton").style.display =
            "none";
          document.getElementById("voiceInputButton").style.display = "none";
          return false;
        }
      }

      // Modified Interactive Chat with STT - Continuous Session
      function startInteractiveChat() {
        if (!recognition) {
          updateAudioStatus("ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™ ÿ∫Ÿäÿ± ŸÖÿØÿπŸàŸÖ");
          return;
        }

        // If session is active, stop it
        if (isInteractiveSessionActive) {
          stopInteractiveSession();
          return;
        }

        // Start new interactive session
        isInteractiveSessionActive = true;
        waitingForResponse = false;

        // Update button appearance
        const button = document.getElementById("interactiveChatButton");
        button.classList.add("listening");
        button.innerHTML = "‚èπÔ∏è"; // Stop icon

        debugLog("Starting interactive session");
        updateAudioStatus("ÿ®ÿØÿ° ÿ¨ŸÑÿ≥ÿ© ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ™ŸÅÿßÿπŸÑŸäÿ© - ÿ™ÿ≠ÿØÿ´ ÿßŸÑÿ¢ŸÜ");

        // Start listening for the first question
        startListeningInSession();
      }

      function stopInteractiveSession() {
        isInteractiveSessionActive = false;
        waitingForResponse = false;

        // Stop any ongoing recognition
        if (recognition && isListeningInteractive) {
          recognition.stop();
        }

        // Clear any pending timeouts
        if (interactiveSessionTimeout) {
          clearTimeout(interactiveSessionTimeout);
          interactiveSessionTimeout = null;
        }

        // Reset button appearance
        const button = document.getElementById("interactiveChatButton");
        button.classList.remove("listening");
        button.innerHTML = "üó£Ô∏è"; // Original icon

        debugLog("Interactive session stopped");
        updateAudioStatus("ÿ™ŸÖ ÿ•ŸÜŸáÿßÿ° ÿ¨ŸÑÿ≥ÿ© ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ™ŸÅÿßÿπŸÑŸäÿ©");

        // Reset status after 2 seconds
        setTimeout(() => {
          updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ©");
        }, 2000);
      }

      function startListeningInSession() {
        if (!isInteractiveSessionActive || waitingForResponse) return;

        // Reset recognition for interactive chat
        recognition.onstart = function () {
          debugLog("Listening in interactive session");
          updateAudioStatus("ÿ¨ÿßÿ±Ÿä ÿßŸÑÿßÿ≥ÿ™ŸÖÿßÿπ... (ÿßÿ∂ÿ∫ÿ∑ ÿßŸÑÿ≤ÿ± ŸÑÿ•ŸÜŸáÿßÿ° ÿßŸÑÿ¨ŸÑÿ≥ÿ©)");
          isListeningInteractive = true;
        };

        recognition.onresult = function (event) {
          let transcript = "";
          for (let i = event.resultIndex; i < event.results.length; i++) {
            if (event.results[i].isFinal) {
              transcript += event.results[i][0].transcript;
            }
          }

          if (transcript && isInteractiveSessionActive) {
            debugLog("Interactive speech recognized:", transcript);
            waitingForResponse = true;
            updateAudioStatus("ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ≥ÿ§ÿßŸÑ...");

            // Process the question
            processQuestionInSession(transcript);
          }
        };

        recognition.onend = function () {
          debugLog("Recognition ended in session");
          isListeningInteractive = false;

          // If session is still active and not waiting for response, restart listening
          if (isInteractiveSessionActive && !waitingForResponse) {
            // Add a small delay before restarting
            setTimeout(() => {
              if (isInteractiveSessionActive && !waitingForResponse) {
                startListeningInSession();
              }
            }, 1000);
          }
        };

        recognition.onerror = function (event) {
          debugLog("Interactive session error", event.error);
          isListeningInteractive = false;

          // Handle different types of errors
          if (event.error === "no-speech") {
            // For no-speech, just restart listening if session is active
            if (isInteractiveSessionActive && !waitingForResponse) {
              setTimeout(() => {
                startListeningInSession();
              }, 1000);
            }
          } else {
            // For other errors, show message but keep session active
            handleSpeechError(event.error);
            if (isInteractiveSessionActive && !waitingForResponse) {
              setTimeout(() => {
                startListeningInSession();
              }, 2000);
            }
          }
        };

        try {
          recognition.start();
          debugLog("Started listening in interactive session");
        } catch (error) {
          debugLog("Error starting recognition in session", error);
          updateAudioStatus("ÿÆÿ∑ÿ£ ŸÅŸä ÿ®ÿØÿ° ÿßŸÑÿßÿ≥ÿ™ŸÖÿßÿπ");

          // Retry after a short delay
          setTimeout(() => {
            if (isInteractiveSessionActive && !waitingForResponse) {
              startListeningInSession();
            }
          }, 1000);
        }
      }

      // Process question within interactive session
      async function processQuestionInSession(question) {
        if (!question.trim() || !isInteractiveSessionActive) return;

        debugLog("Processing question in session", { question });

        try {
          // Resume audio context if suspended
          if (head.audioCtx.state === "suspended") {
            await head.audioCtx.resume();
          }

          updateAudioStatus("ÿßŸÑÿ®ÿßÿ¥ÿß ŸäŸÅŸÉÿ± ŸÅŸä ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©...");

          // Get answer from RAG system
          const result = await getAnswer(question);
          if (result.error) throw new Error(result.error);

          // Update UI with answer
          const answerDiv = document.getElementById("result");
          answerDiv.innerHTML = `
            <h3>ÿßŸÑÿ≥ÿ§ÿßŸÑ:</h3>
            <p style="line-height: 1.6; margin-bottom: 15px; color: #87CEEB;">${question}</p>
            <h3>ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©:</h3>
            <p style="line-height: 1.8;">${result.answer}</p>
          `;

          updateAudioStatus("ÿßŸÑÿ®ÿßÿ¥ÿß Ÿäÿ™ÿ≠ÿØÿ´...");

          // Translate and speak the answer
          const translatedAnswer = await translateToEnglish(result.answer);

          // Speak the answer
          await speakText(result.answer, translatedAnswer);

          // After speaking, if session is still active, wait for next question
          if (isInteractiveSessionActive) {
            waitingForResponse = false;
            updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ™ÿßŸÑŸä... (ÿßÿ∂ÿ∫ÿ∑ ÿßŸÑÿ≤ÿ± ŸÑÿ•ŸÜŸáÿßÿ°)");

            // Start listening for the next question after a short delay
            setTimeout(() => {
              if (isInteractiveSessionActive && !waitingForResponse) {
                startListeningInSession();
              }
            }, 2000);
          }
        } catch (error) {
          debugLog("Error processing question in session", error);
          updateAudioStatus("ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ÿå ÿ¨ÿßÿ±Ÿä ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ...");

          // Reset waiting state and try to continue session
          waitingForResponse = false;
          if (isInteractiveSessionActive) {
            setTimeout(() => {
              updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ™ÿßŸÑŸä...");
              startListeningInSession();
            }, 3000);
          }
        }
      }

      // Voice Input (STT to text field only)
      function startVoiceInput() {
        if (!recognition) {
          updateAudioStatus("ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™ ÿ∫Ÿäÿ± ŸÖÿØÿπŸàŸÖ");
          return;
        }

        if (isListeningVoiceInput) {
          recognition.stop();
          return;
        }

        // Reset recognition for voice input
        recognition.onstart = function () {
          debugLog("Voice input started");
          updateAudioStatus("ÿ¨ÿßÿ±Ÿä ÿßŸÑÿßÿ≥ÿ™ŸÖÿßÿπ ŸÑŸÑÿ•ÿØÿÆÿßŸÑ ÿßŸÑÿµŸàÿ™Ÿä...");
          document
            .getElementById("voiceInputButton")
            .classList.add("listening");
          isListeningVoiceInput = true;
        };

        recognition.onresult = function (event) {
          let transcript = "";
          for (let i = event.resultIndex; i < event.results.length; i++) {
            if (event.results[i].isFinal) {
              transcript += event.results[i][0].transcript;
            }
          }

          if (transcript) {
            document.getElementById("text").value = transcript;
            debugLog("Voice input recognized:", transcript);
          }
        };

        recognition.onend = function () {
          debugLog("Voice input ended");
          updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ©");
          document
            .getElementById("voiceInputButton")
            .classList.remove("listening");
          isListeningVoiceInput = false;
        };

        recognition.onerror = function (event) {
          debugLog("Voice input error", event.error);
          handleSpeechError(event.error);
          document
            .getElementById("voiceInputButton")
            .classList.remove("listening");
          isListeningVoiceInput = false;
        };

        try {
          recognition.start();
          debugLog("Starting voice input");
        } catch (error) {
          debugLog("Error starting voice input", error);
          updateAudioStatus("ÿÆÿ∑ÿ£ ŸÅŸä ÿ®ÿØÿ° ÿßŸÑÿ•ÿØÿÆÿßŸÑ ÿßŸÑÿµŸàÿ™Ÿä");
        }
      }

      // Enhanced speech error handling for sessions
      function handleSpeechError(error) {
        let errorMessage = "ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™";

        switch (error) {
          case "no-speech":
            errorMessage = "ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ŸÉŸÑÿßŸÖ - ÿ¨ÿßÿ±Ÿä ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ";
            break;
          case "audio-capture":
            errorMessage = "ŸÑÿß ŸäŸÖŸÉŸÜ ÿßŸÑŸàÿµŸàŸÑ ŸÑŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ";
            break;
          case "not-allowed":
            errorMessage = "ÿßŸÑÿ•ÿ∞ŸÜ ŸÖÿ±ŸÅŸàÿ∂ ŸÑŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ";
            break;
          case "network":
            errorMessage = "ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑÿ¥ÿ®ŸÉÿ© - ÿ¨ÿßÿ±Ÿä ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ";
            break;
          case "aborted":
            errorMessage = "ÿ™ŸÖ ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™";
            break;
        }

        updateAudioStatus(errorMessage);
      }

      function updateAudioStatus(message) {
        const audioStatus = document.getElementById("audioStatus");
        if (audioStatus) {
          audioStatus.textContent = message;
          audioStatus.style.display = "block";
        }
      }

      /**
       * Clean text for TTS to avoid API errors
       * @param {string} text The text to clean
       * @returns {string} Cleaned text
       */
      function cleanTextForTTS(text) {
        // Remove special characters that might cause issues
        return text
          .replace(/[^\p{L}\p{N}\p{P}\p{Z}]/gu, "") // Keep only letters, numbers, punctuation and spaces
          .replace(/\s+/g, " ") // Normalize whitespace
          .trim();
      }

      /**
       * Split text into smaller chunks to avoid API errors
       * @param {string} text The text to split
       * @returns {Array<string>} Array of text chunks
       */
      function splitTextIntoChunks(text, maxChunkLength = 800) {
        // Check if text is too long
        if (text.length <= maxChunkLength) {
          return [text];
        }

        // Split text into sentences and process in chunks
        const sentences = text
          .split(/[.!?]+/)
          .filter((s) => s.trim().length > 0);
        const chunks = [];
        let currentChunk = "";

        for (const sentence of sentences) {
          if (currentChunk.length + sentence.length > maxChunkLength) {
            chunks.push(currentChunk);
            currentChunk = sentence;
          } else {
            currentChunk += (currentChunk ? ". " : "") + sentence;
          }
        }

        if (currentChunk) {
          chunks.push(currentChunk);
        }

        return chunks;
      }

      /**
       * Translates Arabic text to English for lipsync purposes
       * @param {string} text The Arabic text to translate
       * @returns {Promise<string>} The translated English text
       */
      async function translateToEnglish(text) {
        try {
          debugLog("Translating text for lipsync purposes");
          // Simple placeholder translation
          // This should be replaced with a real translation service
          return "This is a placeholder translation for lip sync purposes. The avatar will move its lips according to this text while playing the Arabic audio.";
        } catch (error) {
          debugLog("Translation error", error);
          // Fallback to a simple English text
          return "Hello, I am Muhammad Ali Pasha. I will speak to you now.";
        }
      }

      /**
       * Fetch with retry mechanism
       * @param {string} url The URL to fetch
       * @param {Object} options Fetch options
       * @param {number} maxRetries Maximum number of retries
       * @returns {Promise<Response>} Fetch response
       */
      async function fetchWithRetry(url, options, maxRetries = 3) {
        let lastError;

        for (let attempt = 0; attempt < maxRetries; attempt++) {
          try {
            const response = await fetch(url, options);

            // For 400 errors, don't retry as it's likely a client error
            if (response.status === 400) {
              const text = await response.text();
              debugLog(`HTTP 400 Error (attempt ${attempt + 1})`, text);

              // Try to parse as JSON if possible
              try {
                const errorJson = JSON.parse(text);
                throw new Error(
                  `HTTP 400: ${errorJson.error?.message || text}`
                );
              } catch (e) {
                if (e.message.startsWith("HTTP 400")) throw e;
                throw new Error(`HTTP 400: ${text}`);
              }
            }

            if (response.ok) return response;

            // For other errors, wait and retry
            const text = await response.text();
            lastError = new Error(`HTTP ${response.status}: ${text}`);
          } catch (error) {
            lastError = error;

            // Don't retry if it's a client error
            if (error.message.includes("HTTP 400")) throw error;

            // Wait before retrying
            await new Promise((r) => setTimeout(r, 1000 * (attempt + 1)));
          }
        }

        throw lastError;
      }

      /**
       * Enhanced speakText function to work better with sessions
       * @param {string} arabicText The Arabic text to be converted to speech
       * @param {string} englishText The English text for lipsync
       * @param {string} [voiceId=null] The voice used for speech generation
       * @param {Object} [opt=null] TalkingHead options
       * @param {function} [onsubtitles=null] Callback when a word is spoken
       */
      async function speakText(
        arabicText,
        englishText,
        voiceId = null,
        opt = null,
        onsubtitles = null
      ) {
        // Update audio status
        updateAudioStatus("ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÉŸÑÿßŸÖ...");

        // Clean text to avoid API errors
        const cleanedText = cleanTextForTTS(arabicText);
        debugLog("Starting speech synthesis", {
          originalLength: arabicText.length,
          cleanedLength: cleanedText.length,
          englishLength: englishText.length,
        });

        // Split text into chunks if too long
        const textChunks = splitTextIntoChunks(cleanedText);
        if (textChunks.length > 1) {
          debugLog("Text split into chunks", { count: textChunks.length });

          // Process each chunk sequentially
          for (const chunk of textChunks) {
            await speakText(chunk, englishText, voiceId, opt, onsubtitles);
          }
          return;
        }

        // Add an empty item to the queue to ensure that everything stays in order
        const item = { status: 0 };
        speechQueue.push(item);

        try {
          // Resume audio context if suspended
          if (head.audioCtx.state === "suspended") {
            debugLog("Audio context state before resume:", head.audioCtx.state);
            await head.audioCtx.resume();
            debugLog("Audio context state after resume:", head.audioCtx.state);
          }

          // Use ElevenLabs API
          const voice = voiceId || DEFAULT_VOICE_ID;

          debugLog("Sending request to ElevenLabs", {
            textLength: cleanedText.length,
            voiceId: voice,
          });

          // Request
          const response = await fetchWithRetry(`${ttsEndpoint}/${voice}`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "xi-api-key": API_KEY,
            },
            body: JSON.stringify({
              text: cleanedText,
              model_id: "eleven_multilingual_v2",
              voice_settings: {
                stability: 0.5,
                similarity_boost: 0.5,
              },
              voice_language: "ar",
            }),
          });

          debugLog("Response received", { status: response.status });

          // Check if response has audio content
          const contentType = response?.headers?.get("content-type");
          if (!contentType?.includes("audio/")) {
            throw new Error("Response is not audio");
          }

          // Get audio data as ArrayBuffer
          const audioData = await response.arrayBuffer();
          debugLog("Audio data received", { size: audioData.byteLength });

          updateAudioStatus("ŸÅŸÉ ÿ™ÿ¥ŸÅŸäÿ± ÿßŸÑÿµŸàÿ™...");

          // TalkingHead audio object
          const audio = {
            audio: null,
            words: [],
            wtimes: [],
            wdurations: [],
          };

          try {
            // Decode audio data
            audio.audio = await head.audioCtx.decodeAudioData(audioData);
            debugLog("Audio successfully decoded", {
              duration: audio.audio.duration,
              sampleRate: audio.audio.sampleRate,
              numberOfChannels: audio.audio.numberOfChannels,
            });
          } catch (decodeError) {
            debugLog("Audio decode error", decodeError);
            throw new Error("Failed to decode audio data");
          }

          // Split English text into words for lipsync
          const englishWords = englishText.split(/\s+/);
          debugLog("English words for lipsync", { count: englishWords.length });

          // Since ElevenLabs doesn't provide word timestamps, we need to estimate them
          // Distribute words evenly across the audio duration
          const audioDuration = audio.audio.duration * 1000; // Convert to milliseconds
          const wordCount = englishWords.length;

          if (wordCount > 0) {
            const wordDuration = audioDuration / wordCount;

            for (let i = 0; i < wordCount; i++) {
              const start = Math.round(i * wordDuration);
              const duration = Math.round(wordDuration);

              audio.words.push(englishWords[i]);
              audio.wtimes.push(start);
              audio.wdurations.push(duration);
            }
          } else {
            // Fallback if no words
            audio.words.push("word");
            audio.wtimes.push(0);
            audio.wdurations.push(audioDuration);
          }

          debugLog("Words mapped for lipsync", { count: audio.words.length });

          // Add audio, options and onSubtitles callback
          item.audio = audio;
          if (opt) item.opt = opt;
          if (onsubtitles) item.onsubtitles = onsubtitles;
        } catch (error) {
          debugLog("Speech synthesis error", error);
          updateAudioStatus("ÿÆÿ∑ÿ£: " + error.message);
          setTimeout(() => {
            if (isInteractiveSessionActive) {
              updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ™ÿßŸÑŸä...");
            } else {
              updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ©");
            }
          }, 3000);
        } finally {
          // Set item ready and process the queue
          item.status = 1;
          processQueue();
        }
      }

      // Process speech queue
      function processQueue() {
        while (speechQueue.length) {
          const item = speechQueue[0];
          if (item.status === 0) break; // The first item is not ready yet
          speechQueue.shift();
          if (item.hasOwnProperty("audio")) {
            try {
              updateAudioStatus("ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿµŸàÿ™...");
              debugLog("Playing audio", { wordCount: item.audio.words.length });

              // Create a gain node to amplify the sound
              const gainNode = head.audioCtx.createGain();
              gainNode.gain.value = 2.0; // Double the volume

              // Apply gain to the audio before playing
              const originalConnect = item.audio.audio.connect;
              item.audio.audio.connect = function (destination) {
                originalConnect.call(this, gainNode);
                gainNode.connect(destination);
              };

              head.speakAudio(item.audio, item.opt, item.onsubtitles);

              // Hide status after playback starts
              setTimeout(() => {
                if (isInteractiveSessionActive) {
                  updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ™ÿßŸÑŸä...");
                } else {
                  updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ©");
                }
              }, 2000);
            } catch (error) {
              debugLog("Audio playback error", error);
              updateAudioStatus("ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑÿ™ÿ¥ÿ∫ŸäŸÑ: " + error.message);
            }
          } else {
            debugLog("No audio data available");
            updateAudioStatus("ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ®ŸäÿßŸÜÿßÿ™ ÿµŸàÿ™Ÿäÿ© ŸÖÿ™ÿßÿ≠ÿ©");
          }
        }
      }

      // Simple test function to verify audio works
      function testAudio() {
        updateAudioStatus("ÿßÿÆÿ™ÿ®ÿßÿ± ÿßŸÑÿµŸàÿ™...");

        try {
          debugLog("Testing audio playback");
          if (head.audioCtx.state === "suspended") {
            debugLog("Audio context suspended, resuming");
            head.audioCtx.resume().then(() => {
              debugLog("Audio context resumed");
              playTestTone();
            });
          } else {
            debugLog("Audio context already active");
            playTestTone();
          }
        } catch (error) {
          debugLog("Test audio error", error);
          updateAudioStatus("ŸÅÿ¥ŸÑ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±: " + error.message);
        }

        function playTestTone() {
          debugLog("Playing test tone");
          const oscillator = head.audioCtx.createOscillator();
          oscillator.type = "sine";
          oscillator.frequency.setValueAtTime(440, head.audioCtx.currentTime);

          // Add gain to make sure the test tone is audible
          const gainNode = head.audioCtx.createGain();
          gainNode.gain.value = 0.5;

          oscillator.connect(gainNode);
          gainNode.connect(head.audioCtx.destination);

          oscillator.start();
          setTimeout(() => {
            oscillator.stop();
            debugLog("Test tone completed");
            updateAudioStatus("ÿßŸÉÿ™ŸÖŸÑ ÿßÿÆÿ™ÿ®ÿßÿ± ÿßŸÑÿµŸàÿ™");
            setTimeout(() => {
              updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ©");
            }, 1000);
          }, 1000);
        }
      }

      // Fallback TTS using Web Speech API
      function fallbackSpeak(text) {
        debugLog("Using fallback Web Speech API");
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = "ar-SA"; // Arabic
        speechSynthesis.speak(utterance);
      }

      // Get available voices from ElevenLabs
      async function getAvailableVoices() {
        try {
          debugLog("Fetching available voices");
          const response = await fetch(voicesEndpoint, {
            method: "GET",
            headers: {
              "xi-api-key": API_KEY,
            },
          });

          if (!response.ok) {
            throw new Error(`HTTP ${response.status}`);
          }

          const data = await response.json();
          debugLog("Voices fetched", { count: data.voices?.length || 0 });
          return data.voices || [];
        } catch (error) {
          debugLog("Error fetching voices", error);
          return [];
        }
      }

      async function getAnswer(question) {
        try {
          debugLog("Fetching answer for question", { question });
          const response = await fetch(API_ENDPOINT, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              character_name: "ŸÖÿ≠ŸÖÿØ ÿπŸÑŸä ÿ®ÿßÿ¥ÿß", // Hardcoded for this page
              question: question,
            }),
          });

          if (!response.ok) throw new Error("API request failed");
          const data = await response.json();

          debugLog("Answer received", {
            answerLength: data.data.answer.length,
          });
          return {
            answer: data.data.answer,
            sources: data.data.sources,
          };
        } catch (error) {
          debugLog("API Error", error);
          return { error: error.message };
        }
      }

      // Process question (used by send button)
      async function processQuestion(question) {
        if (!question.trim()) return;

        debugLog("Processing question", { question });

        // Resume audio context if suspended (needed for browsers with autoplay policy)
        if (head.audioCtx.state === "suspended") {
          try {
            debugLog("Resuming audio context");
            await head.audioCtx.resume();
            debugLog("Audio context resumed on user interaction");
          } catch (error) {
            debugLog("Failed to resume audio context", error);
          }
        }

        // Show loading state
        const loading = document.createElement("div");
        loading.className = "loading";
        loading.innerHTML = `
          <div>ÿßÿ≥ÿ™ÿ¥ÿßÿ±ÿ© ÿßŸÑÿ®ÿßÿ¥ÿß...</div>
          <div style="margin-top: 10px; font-size: 14px;">üïå ‚öîÔ∏è üïå</div>
        `;
        document.body.appendChild(loading);

        try {
          // Get answer from RAG system
          const result = await getAnswer(question);
          if (result.error) throw new Error(result.error);

          // Update UI with answer
          const answerDiv = document.getElementById("result");
          answerDiv.innerHTML = `
          <h3>ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©:</h3>
          <p style="line-height: 1.8;">${result.answer}</p>
        `;

          // Translate the Arabic answer to English for lipsync
          const translatedAnswer = await translateToEnglish(result.answer);
          debugLog("Translation complete", {
            originalLength: result.answer.length,
            translatedLength: translatedAnswer.length,
          });

          // Speak the answer through avatar - Arabic audio with English lipsync
          await speakText(
            result.answer,
            translatedAnswer,
            document.getElementById("voice").value
          );
        } catch (error) {
          debugLog("Error processing speech", error);
          alert(`ÿÆÿ∑ÿ£: ${error.message}`);
        } finally {
          document.body.removeChild(loading);
        }
      }

      // Send button functionality
      function sendMessage() {
        const question = document.getElementById("text").value.trim();
        if (question) {
          processQuestion(question);
          document.getElementById("text").value = ""; // Clear input after sending
        }
      }

      // Create animated particles
      function createParticles() {
        const particles = document.querySelector(".particles");
        const particleCount = 50;

        for (let i = 0; i < particleCount; i++) {
          const particle = document.createElement("div");
          particle.className = "particle";
          particle.style.left = Math.random() * 100 + "%";
          particle.style.animationDelay = Math.random() * 6 + "s";
          particle.style.animationDuration = Math.random() * 3 + 3 + "s";
          particles.appendChild(particle);
        }
      }

      document.addEventListener("DOMContentLoaded", async function (e) {
        // Create particles effect
        createParticles();

        // Create debug info element
        const debugInfo = document.createElement("div");
        debugInfo.id = "debugInfo";
        document.body.appendChild(debugInfo);

        // Create audio status element
        const audioStatus = document.createElement("div");
        audioStatus.id = "audioStatus";
        audioStatus.style.display = "none";
        document.body.appendChild(audioStatus);

        debugLog("Initializing TalkingHead");

        // Instantiate the class
        const nodeAvatar = document.getElementById("avatar");
        head = new TalkingHead(nodeAvatar, {
          ttsEndpoint: "N/A",
          lipsyncModules: ["en"], // Using English for lipsync
          cameraView: "upper",
        });

        // Load and show the avatar
        const nodeInfo = document.getElementById("info");
        try {
          nodeInfo.textContent = "ÿ¨ÿßÿ±Ÿä ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ...";
          debugLog("Loading avatar model");
          await head.showAvatar(
            {
              url: "https://models.readyplayer.me/682f5b3ddb2234a7fa2bc253.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&textureSizeLimit=1024&textureFormat=png",
              body: "M",
              avatarMood: "neutral",
              lipsyncLang: "en", // Using English for lipsync
            },
            (ev) => {
              if (ev.lengthComputable) {
                let val = Math.min(
                  100,
                  Math.round((ev.loaded / ev.total) * 100)
                );
                nodeInfo.textContent = "ÿ¨ÿßÿ±Ÿä ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ " + val + "%";
              }
            }
          );
          nodeInfo.style.display = "none";
          debugLog("Avatar loaded successfully");

          // Initialize Speech Recognition after avatar loads
          const sttSupported = initializeSpeechRecognition();
          if (sttSupported) {
            updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ŸàÿßŸÑÿßÿ≥ÿ™ŸÖÿßÿπ");
          } else {
            updateAudioStatus("ÿ¨ÿßŸáÿ≤ ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ©");
          }

          // Fetch available voices
          getAvailableVoices().then((voices) => {
            if (voices.length > 0) {
              debugLog(
                "Available voices",
                voices.map((v) => `${v.name} (${v.voice_id})`)
              );
              console.log(voices.map((v) => `${v.name} (${v.voice_id})`));
            }
          });
        } catch (error) {
          debugLog("Avatar loading error", error);
          nodeInfo.textContent = error.toString();
        }

        // Button event listeners
        document
          .getElementById("sendButton")
          .addEventListener("click", sendMessage);
        document
          .getElementById("interactiveChatButton")
          .addEventListener("click", startInteractiveChat);
        document
          .getElementById("voiceInputButton")
          .addEventListener("click", startVoiceInput);

        // Enter key support
        document
          .getElementById("text")
          .addEventListener("keypress", function (e) {
            if (e.key === "Enter") {
              sendMessage();
            }
          });

        // Control buttons functionality
        document.getElementById("testBtn").addEventListener("click", testAudio);
        document
          .getElementById("fallbackBtn")
          .addEventListener("click", () =>
            fallbackSpeak("ŸÖÿ±ÿ≠ÿ®ÿßÿå ÿ£ŸÜÿß ŸÖÿ≠ŸÖÿØ ÿπŸÑŸä ÿ®ÿßÿ¥ÿß")
          );
        document.getElementById("debugBtn").addEventListener("click", () => {
          const debugPanel = document.getElementById("debugInfo");
          debugPanel.style.display =
            debugPanel.style.display === "none" ? "block" : "none";
        });

        // Pause animation when document is not visible
        document.addEventListener("visibilitychange", async function (ev) {
          if (document.visibilityState === "visible") {
            debugLog("Page visible, starting animation");
            head.start();
          } else {
            debugLog("Page hidden, stopping animation");
            head.stop();
          }
        });

        // Initialize audio context with user interaction
        document.body.addEventListener(
          "click",
          function () {
            if (head.audioCtx.state === "suspended") {
              debugLog("Initializing audio context with user interaction");
              head.audioCtx.resume().then(() => {
                debugLog("Audio context initialized");
              });
            }
          },
          { once: true }
        );
      });
    </script>
  </head>

  <body>
    <!-- Animated background particles -->
    <div class="particles"></div>

    <!-- Islamic pattern overlay -->
    <div class="islamic-pattern"></div>

    <!-- Avatar section -->
    <div id="avatar"></div>

    <!-- Controls panel -->
    <div id="controls">
      <div class="title-section">
        <h1 class="main-title">ŸÖÿ≠ŸÖÿØ ÿπŸÑŸä ÿ®ÿßÿ¥ÿß</h1>
        <p class="subtitle">The Architect of Modern Egypt</p>
      </div>

      <div class="description">
        ŸÖÿ≠ŸÖÿØ ÿπŸÑŸä ÿ®ÿßÿ¥ÿßÿå ÿßŸÑÿ∞Ÿä ŸäŸèÿ∑ŸÑŸÇ ÿπŸÑŸäŸá ÿ∫ÿßŸÑÿ®ÿßŸã "ÿ£ÿ®Ÿà ŸÖÿµÿ± ÿßŸÑÿ≠ÿØŸäÿ´ÿ©"ÿå ŸÉÿßŸÜ ÿ≠ÿßŸÉŸÖÿßŸã
        ÿπÿ´ŸÖÿßŸÜŸäÿßŸã ÿ™ÿ≠ŸàŸäŸÑŸäÿßŸã ŸÖŸÜ ÿ£ÿµŸÑ ÿ£ŸÑÿ®ÿßŸÜŸä ÿ£ÿπÿßÿØ ÿ™ÿ¥ŸÉŸäŸÑ ŸÖÿµÿ± ÿ®ÿ¥ŸÉŸÑ ÿ¨ÿ∞ÿ±Ÿä ÿÆŸÑÿßŸÑ ÿ£Ÿàÿßÿ¶ŸÑ
        ÿßŸÑŸÇÿ±ŸÜ ÿßŸÑÿ™ÿßÿ≥ÿπ ÿπÿ¥ÿ±. ŸÜŸáÿ∂ ŸÖŸÜ ÿ£ÿµŸàŸÑ ÿπÿ≥ŸÉÿ±Ÿäÿ© ŸÖÿ™Ÿàÿßÿ∂ÿπÿ©ÿå Ÿàÿ£ÿ≥ÿ≥ ÿ≥ŸÑÿßŸÑÿ© ŸÇŸàŸäÿ© ŸàŸÜŸÅÿ∞
        ÿ•ÿµŸÑÿßÿ≠ÿßÿ™ ÿ¥ÿßŸÖŸÑÿ© ÿ≠ÿØÿ´ÿ™ ŸÖÿµÿ± Ÿàÿ™ÿ≠ÿØÿ™ ÿßŸÑŸáŸäÿßŸÉŸÑ ÿßŸÑÿ≥ŸÑÿ∑ŸàŸäÿ© ÿßŸÑÿ™ŸÇŸÑŸäÿØŸäÿ© ŸÑŸÑÿ•ŸÖÿ®ÿ±ÿßÿ∑Ÿàÿ±Ÿäÿ©
        ÿßŸÑÿπÿ´ŸÖÿßŸÜŸäÿ©.
      </div>

      <div id="result"></div>

      <div class="input-container">
        <div class="text-input-wrapper">
          <input
            id="text"
            type="text"
            placeholder="ÿßŸÉÿ™ÿ® ÿ≥ÿ§ÿßŸÑŸÉ ŸáŸÜÿß..."
            value=""
          />
        </div>

        <div class="action-buttons">
          <div class="button-group">
            <button id="sendButton" class="action-button" title="ÿ•ÿ±ÿ≥ÿßŸÑ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ©">
              ‚û§
            </button>
            <div class="button-label">ÿ•ÿ±ÿ≥ÿßŸÑ</div>
          </div>

          <div class="button-group">
            <button
              id="interactiveChatButton"
              class="action-button"
              title="ŸÖÿ≠ÿßÿØÿ´ÿ© ÿ™ŸÅÿßÿπŸÑŸäÿ©"
            >
              üó£Ô∏è
            </button>
            <div class="button-label">ŸÖÿ≠ÿßÿØÿ´ÿ© ÿ™ŸÅÿßÿπŸÑŸäÿ©</div>
          </div>

          <div class="button-group">
            <button
              id="voiceInputButton"
              class="action-button"
              title="ÿ•ÿØÿÆÿßŸÑ ÿµŸàÿ™Ÿä"
            >
              üé§
            </button>
            <div class="button-label">ÿ•ÿØÿÆÿßŸÑ ÿµŸàÿ™Ÿä</div>
          </div>
        </div>
      </div>

      <div class="control-buttons">
        <button id="testBtn" class="control-btn">ÿßÿÆÿ™ÿ®ÿßÿ± ÿßŸÑÿµŸàÿ™</button>
        <button id="fallbackBtn" class="control-btn">ÿµŸàÿ™ ÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿä</button>
        <button id="debugBtn" class="control-btn">ÿ•ÿ∏Ÿáÿßÿ± ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ</button>
      </div>

      <!-- Hidden inputs -->
      <input id="voice" type="hidden" value="VMy40598IGgDeaOE8phq" />
      <input id="apikey" type="hidden" />
    </div>

    <div id="info"></div>
  </body>
</html>
